{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using customized model with python-mldb\n",
    "\n",
    "You can add your own model into our development pipeline. It is easy to combine the model you want with python-mldb, thus utilize the advantages of MySQL database with machine learning application development.\n",
    "\n",
    "### Dealer\n",
    "You can access python-mldb with one object, Dealer. Dealer can access database, train model and save it to database, load model from database and use it to predict.  \n",
    "When Dealer object establish, it can load *.csv file into database through dealer.dataset.\n",
    "Dealer can start a training procedure with the dataset using dealer.procedure.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnny/my_repo/python-mldb/Example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from python_mldb import Dealer\n",
    "\n",
    "\n",
    "path = os.path.abspath('./')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n",
      "Query: SHOW DATABASES; done.\n",
      "Warning: Database test already existed!\n",
      "Warning: cursor is empty!\n",
      "Query: USE test done.\n",
      "Dealer established, service start!\n"
     ]
    }
   ],
   "source": [
    "dealer = Dealer.Dealer(os.path.join(path, 'config_file/config.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.dataset\n",
    "#### Save into database\n",
    "Now we will load .csv file into database. Here we use Titanic Competition data from Kaggle. You can download the file on the [competition page in Kaggle](https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster).\n",
    "We load train.csv and test.csv using dealer.dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Warning: Table TitanicTrain already existed!\n",
      "Query: SHOW TABLES; done.\n",
      "Warning: Table TitanicTest already existed!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(path, '../data/')\n",
    "os.path.exists(data_path)\n",
    "\n",
    "train_data_name = 'TitanicTrain'\n",
    "test_data_name = 'TitanicTest'\n",
    "\n",
    "train_data_path = os.path.join(data_path, 'train.csv')\n",
    "test_data_path = os.path.join(data_path, 'test.csv')\n",
    "\n",
    "dealer.dataset.save_to_database(train_data_path, train_data_name)\n",
    "dealer.dataset.save_to_database(test_data_path, test_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load from database\n",
    "Let's check the data we just save into database. Dealer.dataset.load_from_database will return a pandas.dataframe if the table you want to access exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTest done.\n",
      "Query: SELECT * FROM TitanicTest done.\n"
     ]
    }
   ],
   "source": [
    "train_data = dealer.dataset.load_from_database(train_data_name)\n",
    "test_data = dealer.dataset.load_from_database(test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data feture : \n",
      " Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Train data feature \n",
      ":  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "First 5 elements : \n",
      "\n",
      "['892' '3' 'Kelly, Mr. James' 'male' '34.5' '0' '0' '330911' '7.8292'\n",
      " '0.0' 'Q']\n",
      "['893' '3' 'Wilkes, Mrs. James (Ellen Needs)' 'female' '47.0' '1' '0'\n",
      " '363272' '7.0' '0.0' 'S']\n",
      "['894' '2' 'Myles, Mr. Thomas Francis' 'male' '62.0' '0' '0' '240276'\n",
      " '9.6875' '0.0' 'Q']\n",
      "['895' '3' 'Wirz, Mr. Albert' 'male' '27.0' '0' '0' '315154' '8.6625'\n",
      " '0.0' 'S']\n",
      "['896' '3' 'Hirvonen, Mrs. Alexander (Helga E Lindqvist)' 'female' '22.0'\n",
      " '1' '1' '3101298' '12.2875' '0.0' 'S']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data feture : \\n\", test_data.columns)\n",
    "print(\"Train data feature \\n: \", train_data.columns)\n",
    "print(\"First 5 elements : \\n\")\n",
    "n = 5\n",
    "guests = test_data.head(5).values\n",
    "for guest in guests:\n",
    "    print(guest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['PassengerId', 'Pclass', \n",
    "           'Age', 'SibSp', 'Parch']\n",
    "label = ['Survived']\n",
    "\n",
    "train_x = train_data[feature].values\n",
    "train_y = train_data[label].values\n",
    "\n",
    "test_x = test_data[feature].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.Procedure\n",
    "#### Train using dealer.procedure with data saved into database\n",
    "Register Procedure for dealer, for example here we use random forest classifier. Add to dealer's procedure_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Procedure\n",
    "model_name = 'rf_classifier'\n",
    "rf_classifier = Procedure.RFClassifierProcedure(dealer.query_handler, dealer.dataset, model_name)\n",
    "dealer.procedure_dict[model_name] = rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n",
      "Start training random forest classifier with dataset TitanicTrain.\n",
      "Query: SHOW TABLES; done.\n",
      "Table already existed!\n",
      "Query: INSERT INTO RF_Model VALUES ('rf_classifier','2018-12-21 13:18:24.314725','TitanicTrain','/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T13:18:24.314725_TitanicTrain_rf_classifier.pickle') done.\n",
      "INSERT INTO RF_Model VALUES ('rf_classifier','2018-12-21 13:18:24.314725','TitanicTrain','/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T13:18:24.314725_TitanicTrain_rf_classifier.pickle')\n",
      "Trained model is saved in database test, table RF_Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "procedure = dealer.procedure_dict[model_name]\n",
    "procedure.train(train_data_name, label_col=label, feature_col=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.Function\n",
    "\n",
    "#### Reference\n",
    "We can load the model we just train and saved in database using dealer.function. The process is like using procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Function\n",
    "\n",
    "\n",
    "model_table_name = 'RF_Model'\n",
    "rf_classifier_func = Function.RFClassifierFunction(dealer.query_handler, dealer.dataset, model_name, model_table_name)\n",
    "dealer.function_dict[model_name] = rf_classifier_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SELECT * FROM RF_Model done.\n",
      "('rf_classifier', datetime.datetime(2018, 12, 21, 13, 7, 9), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T13:07:09.347875_TitanicTrain_rf_classifier.pickle')\n",
      "('rf_classifier', datetime.datetime(2018, 12, 21, 13, 18, 24), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T13:18:24.314725_TitanicTrain_rf_classifier.pickle')\n"
     ]
    }
   ],
   "source": [
    "function = dealer.function_dict[model_name]\n",
    "function.show_model(model_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SELECT model_path FROM RF_Model WHERE name='rf_classifier' AND savetime='2018-12-21 13:07:09' AND dataset='TitanicTrain' done.\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTest done.\n",
      "Query: SELECT * FROM TitanicTest done.\n",
      "['0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '1' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '1' '1'\n",
      " '0' '1' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0'\n",
      " '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '1' '0' '1' '1' '0' '1' '1' '0' '0' '1' '0' '1' '0' '0' '1' '0'\n",
      " '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '1'\n",
      " '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1'\n",
      " '0' '1' '0' '0' '0' '0' '1' '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "function.reference(model_name, '2018-12-21 13:07:09', 'TitanicTrain', 'TitanicTest', feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_mldb",
   "language": "python",
   "name": "python_mldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
