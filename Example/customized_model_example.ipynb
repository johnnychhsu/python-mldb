{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using customized model with python-mldb\n",
    "\n",
    "You can add your own model into our development pipeline. It is easy to combine the model you want with python-mldb, thus utilize the advantages of MySQL database with machine learning application development.\n",
    "\n",
    "### Dealer\n",
    "You can access python-mldb with one object, Dealer. Dealer can access database, train model and save it to database, load model from database and use it to predict.  \n",
    "When Dealer object establish, it can load *.csv file into database through dealer.dataset.\n",
    "Dealer can start a training procedure with the dataset using dealer.procedure.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnny/my_repo/python-mldb/Example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from python_mldb import Dealer\n",
    "\n",
    "\n",
    "path = os.path.abspath('./')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n",
      "Query: SHOW DATABASES; done.\n",
      "Warning: Database test already existed!\n",
      "Warning: cursor is empty!\n",
      "Query: USE test done.\n",
      "Dealer established, service start!\n"
     ]
    }
   ],
   "source": [
    "dealer = Dealer.Dealer(os.path.join(path, 'config_file/config.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.dataset\n",
    "#### Save into database\n",
    "Now we will load .csv file into database. Here we use Titanic Competition data from Kaggle. You can download the file on the [competition page in Kaggle](https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster).\n",
    "We load train.csv and test.csv using dealer.dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Warning: Table TitanicTrain already existed!\n",
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Warning: Table TitanicTest already existed!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(path, '../data/')\n",
    "os.path.exists(data_path)\n",
    "\n",
    "train_data_name = 'TitanicTrain'\n",
    "test_data_name = 'TitanicTest'\n",
    "\n",
    "train_data_path = os.path.join(data_path, 'train.csv')\n",
    "test_data_path = os.path.join(data_path, 'test.csv')\n",
    "\n",
    "dealer.dataset.save_to_database(train_data_path, train_data_name)\n",
    "dealer.dataset.save_to_database(test_data_path, test_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load from database\n",
    "Let's check the data we just save into database. Dealer.dataset.load_from_database will return a pandas.dataframe if the table you want to access exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n",
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTest done.\n",
      "Query: SELECT * FROM TitanicTest done.\n"
     ]
    }
   ],
   "source": [
    "train_data = dealer.dataset.load_from_database(train_data_name)\n",
    "test_data = dealer.dataset.load_from_database(test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data feture : \n",
      " Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Train data feature \n",
      ":  Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "First 5 elements : \n",
      "\n",
      "['892' '3' 'Kelly, Mr. James' 'male' '34.5' '0' '0' '330911' '7.8292'\n",
      " '0.0' 'Q']\n",
      "['893' '3' 'Wilkes, Mrs. James (Ellen Needs)' 'female' '47.0' '1' '0'\n",
      " '363272' '7.0' '0.0' 'S']\n",
      "['894' '2' 'Myles, Mr. Thomas Francis' 'male' '62.0' '0' '0' '240276'\n",
      " '9.6875' '0.0' 'Q']\n",
      "['895' '3' 'Wirz, Mr. Albert' 'male' '27.0' '0' '0' '315154' '8.6625'\n",
      " '0.0' 'S']\n",
      "['896' '3' 'Hirvonen, Mrs. Alexander (Helga E Lindqvist)' 'female' '22.0'\n",
      " '1' '1' '3101298' '12.2875' '0.0' 'S']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data feture : \\n\", test_data.columns)\n",
    "print(\"Train data feature \\n: \", train_data.columns)\n",
    "print(\"First 5 elements : \\n\")\n",
    "n = 5\n",
    "guests = test_data.head(5).values\n",
    "for guest in guests:\n",
    "    print(guest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['PassengerId', 'Pclass', \n",
    "           'Age', 'SibSp', 'Parch']\n",
    "label = ['Survived']\n",
    "\n",
    "train_x = train_data[feature].values\n",
    "train_y = train_data[label].values\n",
    "\n",
    "test_x = test_data[feature].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.Procedure\n",
    "#### Train using dealer.procedure with data saved into database\n",
    "Register Procedure for dealer, for example here we use Keras binary classifier, which is a MLP model. Add to dealer's procedure_dict.\n",
    "Here we add keras model into CustomizedProcedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Procedure\n",
    "\n",
    "\n",
    "model_name = 'mlp_classifier' \n",
    "model_table_name = 'keras_binary_classifier'\n",
    "mlp_classifier = Procedure.CustomizedClassifierProcedure(dealer.query_handler,\n",
    "                                                         dealer.dataset,\n",
    "                                                         model_name,\n",
    "                                                         model_table_name,\n",
    "                                                         model,\n",
    "                                                         'fit',\n",
    "                                                         'save')\n",
    "dealer.procedure_dict[model_name] = mlp_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n",
      "Start training mlp_classifier classifier (model type : <class 'keras.engine.sequential.Sequential'> ) with dataset TitanicTrain.\n",
      "Epoch 1/100\n",
      "891/891 [==============================] - 0s 163us/step - loss: 5.9586 - acc: 0.5948\n",
      "Epoch 2/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.7034 - acc: 0.6038\n",
      "Epoch 3/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 6.0956 - acc: 0.5600\n",
      "Epoch 4/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.5896 - acc: 0.6072\n",
      "Epoch 5/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.7859 - acc: 0.5859\n",
      "Epoch 6/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.7818 - acc: 0.5870\n",
      "Epoch 7/100\n",
      "891/891 [==============================] - 0s 17us/step - loss: 5.6262 - acc: 0.5836\n",
      "Epoch 8/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 5.7192 - acc: 0.5758\n",
      "Epoch 9/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.5292 - acc: 0.6004\n",
      "Epoch 10/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.6647 - acc: 0.5993\n",
      "Epoch 11/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 5.6429 - acc: 0.5971\n",
      "Epoch 12/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.5203 - acc: 0.5903\n",
      "Epoch 13/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.5963 - acc: 0.5769\n",
      "Epoch 14/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.3085 - acc: 0.5746\n",
      "Epoch 15/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.3874 - acc: 0.5690\n",
      "Epoch 16/100\n",
      "891/891 [==============================] - 0s 17us/step - loss: 5.4441 - acc: 0.5668\n",
      "Epoch 17/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.3406 - acc: 0.5634\n",
      "Epoch 18/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.3941 - acc: 0.5634\n",
      "Epoch 19/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.1589 - acc: 0.5600\n",
      "Epoch 20/100\n",
      "891/891 [==============================] - 0s 20us/step - loss: 4.8429 - acc: 0.5903\n",
      "Epoch 21/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 5.2832 - acc: 0.5253\n",
      "Epoch 22/100\n",
      "891/891 [==============================] - 0s 20us/step - loss: 4.8158 - acc: 0.5376\n",
      "Epoch 23/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 4.5748 - acc: 0.5657\n",
      "Epoch 24/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 4.3463 - acc: 0.5477\n",
      "Epoch 25/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 4.0114 - acc: 0.5488\n",
      "Epoch 26/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 3.7326 - acc: 0.5701\n",
      "Epoch 27/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 3.2953 - acc: 0.5533\n",
      "Epoch 28/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 2.6968 - acc: 0.5477\n",
      "Epoch 29/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 2.3444 - acc: 0.5264\n",
      "Epoch 30/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 1.9218 - acc: 0.5028\n",
      "Epoch 31/100\n",
      "891/891 [==============================] - 0s 21us/step - loss: 1.5898 - acc: 0.5017\n",
      "Epoch 32/100\n",
      "891/891 [==============================] - 0s 20us/step - loss: 1.1416 - acc: 0.5488\n",
      "Epoch 33/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 1.1469 - acc: 0.4961\n",
      "Epoch 34/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.9422 - acc: 0.5062\n",
      "Epoch 35/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.9132 - acc: 0.5185\n",
      "Epoch 36/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.8497 - acc: 0.5342\n",
      "Epoch 37/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.8646 - acc: 0.5342\n",
      "Epoch 38/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.8341 - acc: 0.5645\n",
      "Epoch 39/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7518 - acc: 0.5208\n",
      "Epoch 40/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7597 - acc: 0.5533\n",
      "Epoch 41/100\n",
      "891/891 [==============================] - 0s 20us/step - loss: 0.7668 - acc: 0.5589\n",
      "Epoch 42/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7197 - acc: 0.5567\n",
      "Epoch 43/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7041 - acc: 0.5533\n",
      "Epoch 44/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7630 - acc: 0.6061\n",
      "Epoch 45/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6923 - acc: 0.5915\n",
      "Epoch 46/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7055 - acc: 0.5971\n",
      "Epoch 47/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.7371 - acc: 0.6128\n",
      "Epoch 48/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7128 - acc: 0.6027\n",
      "Epoch 49/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7080 - acc: 0.5971\n",
      "Epoch 50/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7304 - acc: 0.6016\n",
      "Epoch 51/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7069 - acc: 0.6083\n",
      "Epoch 52/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7079 - acc: 0.6094\n",
      "Epoch 53/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6978 - acc: 0.6139\n",
      "Epoch 54/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.7013 - acc: 0.6117\n",
      "Epoch 55/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6815 - acc: 0.6139\n",
      "Epoch 56/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7147 - acc: 0.6061\n",
      "Epoch 57/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7143 - acc: 0.6061\n",
      "Epoch 58/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6971 - acc: 0.6083\n",
      "Epoch 59/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6990 - acc: 0.6094\n",
      "Epoch 60/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7006 - acc: 0.6016\n",
      "Epoch 61/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.7003 - acc: 0.6117\n",
      "Epoch 62/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6912 - acc: 0.6094\n",
      "Epoch 63/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6900 - acc: 0.6105\n",
      "Epoch 64/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6866 - acc: 0.6128\n",
      "Epoch 65/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6855 - acc: 0.6094\n",
      "Epoch 66/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6820 - acc: 0.6195\n",
      "Epoch 67/100\n",
      "891/891 [==============================] - 0s 27us/step - loss: 0.7059 - acc: 0.6150\n",
      "Epoch 68/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6997 - acc: 0.6128\n",
      "Epoch 69/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6839 - acc: 0.6218\n",
      "Epoch 70/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6842 - acc: 0.6173\n",
      "Epoch 71/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6839 - acc: 0.6083\n",
      "Epoch 72/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6800 - acc: 0.6173\n",
      "Epoch 73/100\n",
      "891/891 [==============================] - 0s 21us/step - loss: 0.6743 - acc: 0.6128\n",
      "Epoch 74/100\n",
      "891/891 [==============================] - 0s 17us/step - loss: 0.6942 - acc: 0.6162\n",
      "Epoch 75/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6702 - acc: 0.6139\n",
      "Epoch 76/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6815 - acc: 0.6162\n",
      "Epoch 77/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6801 - acc: 0.6162\n",
      "Epoch 78/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6710 - acc: 0.6162\n",
      "Epoch 79/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6800 - acc: 0.6162\n",
      "Epoch 80/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6794 - acc: 0.6184\n",
      "Epoch 81/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6723 - acc: 0.6139\n",
      "Epoch 82/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6732 - acc: 0.6162\n",
      "Epoch 83/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6697 - acc: 0.6139\n",
      "Epoch 84/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6708 - acc: 0.6207\n",
      "Epoch 85/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6744 - acc: 0.6173\n",
      "Epoch 86/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6762 - acc: 0.6162\n",
      "Epoch 87/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6622 - acc: 0.6162\n",
      "Epoch 88/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6718 - acc: 0.6207\n",
      "Epoch 89/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6843 - acc: 0.6150\n",
      "Epoch 90/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6672 - acc: 0.6184\n",
      "Epoch 91/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6780 - acc: 0.6162\n",
      "Epoch 92/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6795 - acc: 0.6162\n",
      "Epoch 93/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6647 - acc: 0.6173\n",
      "Epoch 94/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6742 - acc: 0.6162\n",
      "Epoch 95/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6588 - acc: 0.6184\n",
      "Epoch 96/100\n",
      "891/891 [==============================] - 0s 19us/step - loss: 0.6709 - acc: 0.6184\n",
      "Epoch 97/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6686 - acc: 0.6173\n",
      "Epoch 98/100\n",
      "891/891 [==============================] - 0s 20us/step - loss: 0.6776 - acc: 0.6173\n",
      "Epoch 99/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6774 - acc: 0.6128\n",
      "Epoch 100/100\n",
      "891/891 [==============================] - 0s 18us/step - loss: 0.6705 - acc: 0.6173\n",
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Table already existed!\n",
      "Query: INSERT INTO keras_binary_classifier VALUES ('mlp_classifier','2018-12-21 15:06:52.170064','TitanicTrain','/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T15:06:52.170064_TitanicTrain_mlp_classifier.h5') done.\n",
      "INSERT INTO keras_binary_classifier VALUES ('mlp_classifier','2018-12-21 15:06:52.170064','TitanicTrain','/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T15:06:52.170064_TitanicTrain_mlp_classifier.h5')\n",
      "Trained model is saved in database test, table keras_binary_classifier.\n"
     ]
    }
   ],
   "source": [
    "procedure = dealer.procedure_dict[model_name]\n",
    "procedure.train(train_data_name, label_col=label, feature_col=feature, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer.Function\n",
    "\n",
    "#### Reference\n",
    "We can load the model we just train and saved in database using dealer.function. The process is like using procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Function\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "rf_classifier_func = Function.CustomizedClassifierFunction(dealer.query_handler, \n",
    "                                                           dealer.dataset, \n",
    "                                                           model_name, \n",
    "                                                           model_table_name,\n",
    "                                                           'predict',\n",
    "                                                           load_model)\n",
    "dealer.function_dict[model_name] = rf_classifier_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SELECT * FROM keras_binary_classifier done.\n",
      "('mlp_classifier', datetime.datetime(2018, 12, 21, 14, 51, 54), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T14:51:54.350580_TitanicTrain_mlp_classifier.h5')\n",
      "('mlp_classifier', datetime.datetime(2018, 12, 21, 14, 55, 15), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T14:55:15.221400_TitanicTrain_mlp_classifier.h5')\n",
      "('mlp_classifier', datetime.datetime(2018, 12, 21, 15, 1, 14), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T15:01:14.366029_TitanicTrain_mlp_classifier.h5')\n",
      "('mlp_classifier', datetime.datetime(2018, 12, 21, 15, 6, 52), 'TitanicTrain', '/home/johnny/my_repo/python-mldb/saved_model/2018-12-21T15:06:52.170064_TitanicTrain_mlp_classifier.h5')\n"
     ]
    }
   ],
   "source": [
    "function = dealer.function_dict[model_name]\n",
    "function.show_model(model_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: cursor is empty!\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW TABLES; done.\n",
      "Query: SHOW COLUMNS FROM TitanicTest done.\n",
      "Query: SELECT * FROM TitanicTest done.\n",
      "Warning: cursor is empty!\n",
      "Query: SELECT model_path FROM keras_binary_classifier WHERE name='mlp_classifier' AND savetime='2018-12-21 14:55:15' AND dataset='TitanicTrain' done.\n",
      "418/418 [==============================] - 0s 62us/step\n",
      "[[0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]\n",
      " [0.4260663]]\n"
     ]
    }
   ],
   "source": [
    "function.reference(model_name, '2018-12-21 14:55:15', train_data_name, test_data_name, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_mldb",
   "language": "python",
   "name": "python_mldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
