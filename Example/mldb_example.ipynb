{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Example using Titanic data\n",
    "In this notebook we demo the usage of python-mldb. You can access python-mldb through a single class, Dealer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnny/my_repo/python-mldb/Example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from python_mldb import Dealer\n",
    "\n",
    "\n",
    "path = os.path.abspath('./')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n",
      "Query: SHOW DATABASES; done.\n",
      "Warning: Database test already existed!\n",
      "Warning: cursor is empty!\n",
      "Query: USE test done.\n",
      "Dealer established, service start!\n"
     ]
    }
   ],
   "source": [
    "dealer = Dealer.Dealer(os.path.join(path, 'config_file/config.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer Intro\n",
    "When Dealer object establish, it can load *.csv file into database through dealer.dataset.\n",
    "Dealer can start a training procedure with the dataset using dealer.procedure.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/johnny/my_repo/python-mldb/Example/../data/train.csv\n",
      "Failed : 1050 (42S01): Table 'TitanicTrain' already exists\n",
      "Query: LOAD DATA LOCAL INFILE '/home/johnny/my_repo/python-mldb/Example/../data/train.csv' INTO TABLE TitanicTrain FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n",
      "' IGNORE 1 LINES done.\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(path, '../data/train.csv')\n",
    "os.path.exists(train_path)\n",
    "print (train_path)\n",
    "\n",
    "raw_data_name = 'TitanicTrain'\n",
    "dealer.dataset.save_to_database(train_path, 'TitanicTrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n"
     ]
    }
   ],
   "source": [
    "# Check the data we just save into database\n",
    "raw_data = dealer.dataset.load_from_database(raw_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "['1' '0' '3' '\"Braund' ' Mr. Owen Harris\"' '0' '22' '1' '0' '0.0' '7.25'\n",
      " '']\n",
      "['2' '1' '1' '\"Cumings' ' Mrs. John Bradley (Florence Briggs Thayer)\"' '0'\n",
      " '38' '1' '0' '0.0' '71.2833' 'C85']\n",
      "['3' '1' '3' '\"Heikkinen' ' Miss. Laina\"' '0' '26' '0' '0' '0.0' '7.925'\n",
      " '']\n",
      "['4' '1' '1' '\"Futrelle' ' Mrs. Jacques Heath (Lily May Peel)\"' '0' '35'\n",
      " '1' '0' '113803.0' '53.1' 'C123']\n",
      "['5' '0' '3' '\"Allen' ' Mr. William Henry\"' '0' '35' '0' '0' '373450.0'\n",
      " '8.05' '']\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.columns)\n",
    "n = 5\n",
    "guests = raw_data.head(5).values\n",
    "for guest in guests:\n",
    "    print(guest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure\n",
    "Dealer.dataset will load the data we save into database, return a pandas.Dataframe object. We now use choose columns we want for our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the feature we want\n",
    "train_feature_list = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "train_label = ['Survived']\n",
    "\n",
    "train_x = raw_data[train_feature_list].values\n",
    "train_y = raw_data[train_label].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with toy data generated by sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'label']\n",
    "X, y = make_classification(n_samples=1000, \n",
    "                           n_features=4,\n",
    "                           n_informative=2, \n",
    "                           n_redundant=0,\n",
    "                           random_state=0, \n",
    "                           shuffle=False)\n",
    "\n",
    "y = np.expand_dims(y, axis=1)\n",
    "feature_label_pair = np.concatenate((X, y), axis=1)\n",
    "\n",
    "toy_data = pd.DataFrame(data=feature_label_pair,\n",
    "                       columns=columns)\n",
    "\n",
    "toy_data_table_name = 'ToyData'\n",
    "with open('toy_data.csv', 'w') as f:\n",
    "    toy_data.to_csv(f, columns=columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed : 1050 (42S01): Table 'ToyData' already exists\n",
      "Query: LOAD DATA LOCAL INFILE 'toy_data.csv' INTO TABLE ToyData FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n",
      "' IGNORE 1 LINES done.\n"
     ]
    }
   ],
   "source": [
    "# Save toy data into database\n",
    "dealer.dataset.save_to_database('toy_data.csv', toy_data_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM ToyData done.\n",
      "Query: SELECT * FROM ToyData done.\n"
     ]
    }
   ],
   "source": [
    "# Check the data we just save into database\n",
    "toy_data = dealer.dataset.load_from_database(toy_data_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature_1', 'feature_2', 'feature_3', 'feature_4', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(toy_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add procedure to dealer's procedure list\n",
    "Choose procedure we want and add it to dealer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Procedure\n",
    "model_name = 'rf_classifier'\n",
    "rf_classifier = Procedure.RFClassifierProcedure(dealer.query_handler, dealer.dataset, model_name)\n",
    "dealer.procedure_dict[model_name] = rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM ToyData done.\n",
      "Query: SELECT * FROM ToyData done.\n",
      "Start training random forest classifier with dataset ToyData.\n",
      "Query: SHOW TABLES; done.\n",
      "Table already existed!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/johnny/my_repo/python-mldb/saved_model/2018-12-14T16:07:39.046496_ToyData_rf_classifier.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1541fd8af966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call the procedure's train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprocedure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocedure_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocedure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoy_data_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/my_repo/python-mldb/python_mldb/Procedure.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_table_name, label_col, feature_col, saved_model_path, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_repo/python-mldb/python_mldb/Procedure.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, data_table_name, label_col, feature_col, saved_model_path, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_table_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_table_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_repo/python-mldb/python_mldb/Procedure.py\u001b[0m in \u001b[0;36m_save_to_db\u001b[0;34m(self, clf, data_table_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mroot_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./../saved_model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/johnny/my_repo/python-mldb/saved_model/2018-12-14T16:07:39.046496_ToyData_rf_classifier.pickle'"
     ]
    }
   ],
   "source": [
    "# Call the procedure's train function\n",
    "procedure = dealer.procedure_dict[model_name]\n",
    "procedure.train(toy_data_table_name, label_col=[columns[4]], feature_col=columns[0: 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_mldb",
   "language": "python",
   "name": "python_mldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
