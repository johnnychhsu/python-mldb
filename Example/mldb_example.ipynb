{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Example using Titanic data\n",
    "In this notebook we demo the usage of python-mldb. You can access python-mldb through a single class, Dealer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnnyhsu/my_repo/python-mldb/Example\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from python_mldb import Dealer\n",
    "\n",
    "\n",
    "path = os.path.abspath('./')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n",
      "Query: SHOW DATABASES; done.\n",
      "Warning: Database test already existed!\n",
      "Query: USE test done.\n",
      "Dealer established, service start!\n"
     ]
    }
   ],
   "source": [
    "dealer = Dealer.Dealer(os.path.join(path, 'config_file/config.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealer Intro\n",
    "When Dealer object establish, it can load *.csv file into database through dealer.dataset.\n",
    "Dealer can start a training procedure with the dataset using dealer.procedure.train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnnyhsu/my_repo/python-mldb/Example/../data/train.csv\n",
      "Failed : 1050 (42S01): Table 'titanictrain' already exists\n",
      "Query: LOAD DATA LOCAL INFILE '/Users/johnnyhsu/my_repo/python-mldb/Example/../data/train.csv' INTO TABLE TitanicTrain FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\n",
      "' IGNORE 1 LINES done.\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(path, '../data/train.csv')\n",
    "os.path.exists(train_path)\n",
    "print (train_path)\n",
    "\n",
    "raw_data_name = 'TitanicTrain'\n",
    "dealer.dataset.save_to_database(train_path, 'TitanicTrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM TitanicTrain done.\n",
      "Query: SELECT * FROM TitanicTrain done.\n"
     ]
    }
   ],
   "source": [
    "# Check the data we just save into database\n",
    "raw_data = dealer.dataset.load_from_database(raw_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "['1' '0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171'\n",
      " '7.25' '' 'S\\r']\n",
      "['2' '1' '1' 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)'\n",
      " 'female' '38' '1' '0' 'PC 17599' '71.2833' 'C85' 'C\\r']\n",
      "['3' '1' '3' 'Heikkinen, Miss. Laina' 'female' '26' '0' '0'\n",
      " 'STON/O2. 3101282' '7.925' '' 'S\\r']\n",
      "['4' '1' '1' 'Futrelle, Mrs. Jacques Heath (Lily May Peel)' 'female' '35'\n",
      " '1' '0' '113803' '53.1' 'C123' 'S\\r']\n",
      "['5' '0' '3' 'Allen, Mr. William Henry' 'male' '35' '0' '0' '373450'\n",
      " '8.05' '' 'S\\r']\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.columns)\n",
    "n = 5\n",
    "guests = raw_data.head(5).values\n",
    "for guest in guests:\n",
    "    print(guest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure\n",
    "Dealer.dataset will load the data we save into database, return a pandas.Dataframe object. We now use choose columns we want for our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the feature we want\n",
    "train_feature_list = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "train_label = ['Survived']\n",
    "\n",
    "train_x = raw_data[train_feature_list].values\n",
    "train_y = raw_data[train_label].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with toy data generated by sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'label']\n",
    "X, y = make_classification(n_samples=1000, \n",
    "                           n_features=4,\n",
    "                           n_informative=2, \n",
    "                           n_redundant=0,\n",
    "                           random_state=0, \n",
    "                           shuffle=False)\n",
    "\n",
    "y = np.expand_dims(y, axis=1)\n",
    "feature_label_pair = np.concatenate((X, y), axis=1)\n",
    "\n",
    "toy_data = pd.DataFrame(data=feature_label_pair,\n",
    "                       columns=columns)\n",
    "\n",
    "toy_data_table_name = 'ToyData'\n",
    "with open('toy_data.csv', 'w') as f:\n",
    "    toy_data.to_csv(f, columns=columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed : 1050 (42S01): Table 'toydata' already exists\n",
      "Query: LOAD DATA LOCAL INFILE 'toy_data.csv' INTO TABLE ToyData FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\n",
      "' IGNORE 1 LINES done.\n"
     ]
    }
   ],
   "source": [
    "# Save toy data into database\n",
    "dealer.dataset.save_to_database('toy_data.csv', toy_data_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM ToyData done.\n",
      "Query: SELECT * FROM ToyData done.\n"
     ]
    }
   ],
   "source": [
    "# Check the data we just save into database\n",
    "toy_data = dealer.dataset.load_from_database(toy_data_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature_1', 'feature_2', 'feature_3', 'feature_4', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(toy_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add procedure to dealer's procedure list\n",
    "Choose model we want for training, register it to dealer's procedure list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_mldb import Procedure\n",
    "model_name = 'rf_classifier'\n",
    "rf_classifier = Procedure.RFClassifierProcedure(dealer.query_handler, dealer.dataset, model_name)\n",
    "dealer.procedure_dict[model_name] = rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW COLUMNS FROM ToyData done.\n",
      "Query: SELECT * FROM ToyData done.\n",
      "Start training random forest classifier with dataset ToyData.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Warning: cursor is empty!\n",
      "Query: CREATE TABLE RF_Model (name VARCHAR(25), savetime DATETIME, dataset VARCHAR(25), model_path VARCHAR(250), CONSTRAINT PK Primary Key (name, savetime, dataset)) done.\n",
      "Warning: cursor is empty!\n",
      "Query: INSERT INTO RF_Model VALUES ('rf_classifier','2018-12-16 01:15:32.214572','ToyData','/Users/johnnyhsu/my_repo/python-mldb/saved_model/2018-12-16T01:15:32.214572_ToyData_rf_classifier.pickle') done.\n",
      "INSERT INTO RF_Model VALUES ('rf_classifier','2018-12-16 01:15:32.214572','ToyData','/Users/johnnyhsu/my_repo/python-mldb/saved_model/2018-12-16T01:15:32.214572_ToyData_rf_classifier.pickle')\n",
      "Trained model is saved in database test, table RF_Model.\n"
     ]
    }
   ],
   "source": [
    "# Call the procedure's train function\n",
    "procedure = dealer.procedure_dict[model_name]\n",
    "procedure.train(toy_data_table_name, label_col=[columns[4]], feature_col=columns[0: 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add function to dealer's function list\n",
    "Choose model we want to use for referencing, register it to dealer's function list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register function for dealer\n",
    "from python_mldb import Function\n",
    "rf_classifier_func = Function.RFClassifierFunction(dealer.query_handler, dealer.dataset, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SELECT * FROM RF_Model done.\n",
      "('rf_classifier', datetime.datetime(2018, 12, 16, 1, 15, 32), 'ToyData', '/Users/johnnyhsu/my_repo/python-mldb/saved_model/2018-12-16T01:15:32.214572_ToyData_rf_classifier.pickle')\n"
     ]
    }
   ],
   "source": [
    "# Show models we have in the database\n",
    "rf_classifier_func.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SHOW TABLES; done.\n",
      "Query: SELECT model_path FROM RF_Model WHERE name='rf_classifier' AND savetime='2018-12-16 01:15:32' AND dataset='ToyData' done.\n",
      "Query: SHOW COLUMNS FROM ToyData done.\n",
      "Query: SELECT * FROM ToyData done.\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Reference using the model and dataset we choose\n",
    "rf_classifier_func.reference(model_name, '2018-12-16 01:15:32', 'ToyData', 'ToyData', columns[0: 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_mldb",
   "language": "python",
   "name": "python_mldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
